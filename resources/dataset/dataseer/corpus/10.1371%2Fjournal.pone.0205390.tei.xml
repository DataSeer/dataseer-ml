<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/lopez/grobid/dataseer-ml/../grobid-home/schemas/xsd/Grobid.xsd">
  <teiHeader xml:lang="en">
    <encodingDesc>
      <appInfo>
        <application ident="GROBID" version="0.5.6-SNAPSHOT" when="2019-07-08T09:25+0000">
          <ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
        </application>
      </appInfo>
    </encodingDesc>
    <fileDesc>
      <titleStmt>
        <title level="a" type="main">PCANet based nonlocal means method for speckle noise removal in ultrasound images</title>
      </titleStmt>
      <publicationStmt>
        <publisher/>
        <availability status="unknown">
          <licence/>
        </availability>
        <date type="published" when="2018-10-12">October 12, 2018</date>
      </publicationStmt>
      <sourceDesc>
        <biblStruct>
          <analytic>
            <author>
              <persName>
                <forename type="first">Houqiang</forename>
                <surname>Yuid</surname>
              </persName>
              <affiliation key="aff0">
                <orgName key="dep1" type="department">Department of Biomedical Engineering</orgName>
                <orgName key="dep2" type="department">School of Life Science and Technology</orgName>
                <orgName type="laboratory">Ministry of Education Key Laboratory of Molecular Biophysics</orgName>
                <orgName type="institution">Huazhong University of Science and Technology</orgName>
                <address>
                  <settlement>Wuhan</settlement>
                  <country key="CN">P.R. China</country>
                </address>
              </affiliation>
            </author>
            <author>
              <persName>
                <forename type="first">Mingyue</forename>
                <surname>Ding</surname>
              </persName>
              <affiliation key="aff0">
                <orgName key="dep1" type="department">Department of Biomedical Engineering</orgName>
                <orgName key="dep2" type="department">School of Life Science and Technology</orgName>
                <orgName type="laboratory">Ministry of Education Key Laboratory of Molecular Biophysics</orgName>
                <orgName type="institution">Huazhong University of Science and Technology</orgName>
                <address>
                  <settlement>Wuhan</settlement>
                  <country key="CN">P.R. China</country>
                </address>
              </affiliation>
            </author>
            <author>
              <persName>
                <forename type="first">Xuming</forename>
                <surname>Zhangid</surname>
              </persName>
              <affiliation key="aff0">
                <orgName key="dep1" type="department">Department of Biomedical Engineering</orgName>
                <orgName key="dep2" type="department">School of Life Science and Technology</orgName>
                <orgName type="laboratory">Ministry of Education Key Laboratory of Molecular Biophysics</orgName>
                <orgName type="institution">Huazhong University of Science and Technology</orgName>
                <address>
                  <settlement>Wuhan</settlement>
                  <country key="CN">P.R. China</country>
                </address>
              </affiliation>
            </author>
            <author>
              <persName>
                <forename type="first">Jinbo</forename>
                <surname>Wu</surname>
              </persName>
              <affiliation key="aff1">
                <orgName type="department">School of Naval Architecture &amp; Ocean Engineering</orgName>
                <orgName type="institution">Huazhong University of Science &amp; Technology</orgName>
                <address>
                  <addrLine>1037 Luoyu Road</addrLine>
                  <settlement>Wuhan</settlement>
                  <country key="CN">P. R. China</country>
                </address>
              </affiliation>
            </author>
            <title level="a" type="main">PCANet based nonlocal means method for speckle noise removal in ultrasound images</title>
          </analytic>
          <monogr>
            <imprint>
              <date type="published" when="2018-10-12">October 12, 2018</date>
            </imprint>
          </monogr>
          <note>RESEARCH ARTICLE 1 / 19</note>
        </biblStruct>
      </sourceDesc>
    </fileDesc>
    <profileDesc>
      <abstract>
        <div>
          <head>Abstract</head>
          <p>
            <s>Speckle reduction remains a critical issue for ultrasound image processing and analysis.</s>
            <s>The nonlocal means (NLM) filter has recently attached much attention due to its competitive despeckling performance.</s>
            <s>However, the existing NLM methods usually determine the similarity between two patches by directly utilizing the gray-level information of the noisy image, which renders it difficult to represent the structural similarity of ultrasound images effectively.</s>
            <s>To address this problem, the NLM method based on the simple deep learning baseline named PCANet is proposed by introducing the intrinsic features of image patches extracted by this network rather than the pixel intensities into the pixel similarity computation.</s>
            <s>In this approach, the improved two-stage PCANet is proposed by using Parametric Rectified Linear Unit (PReLU) activation function instead of the binary hashing and block histograms in the original PCANet.</s>
            <s>This model is firstly trained on the ultrasound database to learn the convolution kernels.</s>
            <s>Then, the trained PCANet is utilized to extract the intrinsic features from the image patches in the pre-denoised version of the noisy image to be despeckled.</s>
            <s>These obtained features are concatenated together to determine the structural similarity between image patches in the NLM method, based on which the weighted mean of all pixels in a search window is computed to produce the final despeckled image.</s>
            <s>Extensive experiments have been conducted on a variety of images to demonstrate the superiority of the proposed method over several well-known despeckling algorithm and the PCANet based NLM method using ReLU function and sigmoid function.</s>
            <s>Visual inspection indicates that the proposed method outperforms the compared methods in reducing speckle noise and preserving image details.</s>
            <s>The quantitative comparisons show that among all the evaluated methods, our method produces the best structural similarity index metrics (SSIM) values for the synthetic image, as well as the highest equivalent number of looks (ENL) value for the simulated image and the clinical ultrasound images.</s>
          </p>
        </div>
      </abstract>
    </profileDesc>
  </teiHeader>
  <text xml:lang="en">
    <body>
      <div>
        <p>
          <s>a1111111111 a1111111111 a1111111111 a1111111111 a1111111111</s>
        </p>
      </div>
      <div>
        <head n="1">Introduction</head>
        <p>
          <s>Medical imaging plays a critical role in disease monitoring and diagnosis.</s>
          <s>Compared with other imaging techniques such as X-ray, CT and MRI, ultrasound imaging is a noninvasive, real-time and radiation-free imaging modality.</s>
          <s>However, the ultrasound images are inevitably corrupted by speckle noise due to the coherent imaging mechanism from the scatters <ref target="#b0" type="bibr">[1]</ref> .</s>
          <s>Such a noise reduces the sharpness of image details and complicates the diagnosis of the tiny structure of lesions.</s>
          <s>Therefore, despeckling is of great significance for improving ultrasound image quality.</s>
          <s>Moreover, as a pre-processing step, denoising will also benefit image post-processing tasks such as image segmentation, classification and registration.</s>
        </p>
        <p>
          <s>In ultrasound imaging, speckle noise has a random granular pattern.</s>
          <s>The distribution of speckle noise is signal dependent and is governed by Fisher-Tippett distribution <ref target="#b1" type="bibr">[2]</ref> or Gamma distribution <ref target="#b2" type="bibr">[3]</ref> , which can be represented <ref target="#b3" type="bibr">[4,</ref>
            <ref target="#b4" type="bibr">5]</ref> where (x,y) is the pixel location, v(x,y) is the clean image, u(x,y) is the noisy image, η is a Gaussian noise distribution with zero-mean and variance σ 2 , and the factor γ is related to the ultrasound devices and additional processing.</s>
          <s>Extensive studies indicate that γ = 0.5 can be used to model speckle noise in the ultrasound images <ref target="#b3" type="bibr">[4,</ref>
            <ref target="#b5" type="bibr">6]</ref> .</s>
        </p>
        <p>
          <s>Many methods have been developed for ultrasound images despeckling <ref target="#b6" type="bibr">[7]</ref> .</s>
          <s>In general, the existing despeckling methods can be classified as the spatial domain based methods and the frequency domain based ones.</s>
          <s>The traditional spatial domain based methods, such as Frost filter <ref target="#b7" type="bibr">[8]</ref> , Kuan filter <ref target="#b8" type="bibr">[9]</ref> , squeeze box filter (SBF) <ref target="#b9" type="bibr">[10]</ref> and speckle reducing anisotropic diffusion (SRAD) filter <ref target="#b10" type="bibr">[11]</ref> , are based on the local comparison of pixels.</s>
          <s>One disadvantage of these approaches is that they cannot deliver sufficient noise reduction while preserving image details effectively.</s>
          <s>For the frequency domain based methods, the most popular techniques are the wavelet based methods <ref target="#b11" type="bibr">[12]</ref>
            <ref target="#b12" type="bibr">[13]</ref>
            <ref target="#b13" type="bibr">[14]</ref> .</s>
          <s>These methods work by transforming speckle noise into additive noise and then removing it within the wavelet domain.</s>
          <s>They tend to introduce the artifacts related to the choice of mother wavelet.</s>
        </p>
        <p>
          <s>Recently, the nonlocal means (NLM) filter proposed by Buades et al. <ref target="#b14" type="bibr">[15]</ref> is considered as a state-of-the-art algorithm for eliminating the additive noise.</s>
          <s>This method explores the selfsimilarities between image patches instead of individual pixels, and each image pixel is restored by the weighted average of all pixels in a search window.</s>
          <s>Nowadays, the NLM method has been widely applied to denoise the medical images such as MR images and CT images <ref target="#b15" type="bibr">[16]</ref>
            <ref target="#b16" type="bibr">[17]</ref>
            <ref target="#b17" type="bibr">[18]</ref> .</s>
          <s>Despite the success in removing Gaussian noise, the traditional nonlocal means (TNLM) method by its very nature becomes unsuitable for speckle noise reduction since speckle noise is different from Gaussian noise significantly.</s>
          <s>To overcome this drawback, several modified NLM-based approaches have been presented <ref target="#b4" type="bibr">[5,</ref>
            <ref target="#b18" type="bibr">[19]</ref>
            <ref target="#b19" type="bibr">[20]</ref>
            <ref target="#b20" type="bibr">[21]</ref>
            <ref target="#b21" type="bibr">[22]</ref> for despeckling.</s>
          <s>Specifically, Zhan et al. <ref target="#b4" type="bibr">[5]</ref> have proposed a weight refining method for speckle noise reduction in which the weights are calculated in the lower-dimensional principal component analysis (PCA) subspace.</s>
          <s>Coupe et al. <ref target="#b18" type="bibr">[19]</ref> have introduced the optimized Bayesian nonlocal means (OBNLM) filter.</s>
          <s>In contrast to the TNLM, the OBNLM filter determines the similarity between two image patches based on the Pearson distance derived by the Bayesian framework instead of the Euclidean distance of TNLM approach.</s>
          <s>Yang et al. <ref target="#b20" type="bibr">[21]</ref> have presented a hybrid despeckling approach which combines the NLM with the local statistics of noise (NLMLS).</s>
          <s>In this method, the local statistics of speckle noise are used to pre-filter the ultrasound image and the similarity is computed based on the pre-filtered image to produce the final denoised result.</s>
          <s>Two total variation (TV) model based NLM methods have been proposed by Dong et al. <ref target="#b21" type="bibr">[22]</ref> to reduce the multiplicative noise.</s>
          <s>Compared with the classical TV-based methods, the nonlocal TV methods perform better in preserving image textures and repetitive structures.</s>
          <s>The above-mentioned methods as the extension of TNLM method have contributed to the development of ultrasound image restoration techniques.</s>
        </p>
        <p>
          <s>However, most of the NLM-based despeckling methods depend on the utilization of graylevel information and hand-crafted features.</s>
          <s>These features are not sufficient to accurately represent the structural similarity between image patches in the ultrasound images.</s>
          <s>If the intrinsic features can be learned from the images of interest for structural similarity computation, the better despeckled results can be obtained.</s>
        </p>
        <p>
          <s>Deep learning, as a popular algorithm within the research community of machine learning, can automatically learn the intrinsic features from the training data.</s>
          <s>Up to now, various deep learning models, such as deep belief network (DBN), stacked auto-encode (SAE), convolutional neural networks (CNN) and nonlocal deep network <ref target="#b22" type="bibr">[23]</ref> , have been proposed.</s>
          <s>Among these models, the CNN is very popular due to the use of convolutional architectures.</s>
          <s>In recent years, many CNN-based variations have been introduced and successfully applied to various visual tasks such as feature extraction, classification <ref target="#b23" type="bibr">[24,</ref>
            <ref target="#b24" type="bibr">25]</ref> , super-resolution <ref target="#b25" type="bibr">[26]</ref> , object detection <ref target="#b26" type="bibr">[27,</ref>
            <ref target="#b28" type="bibr">28]</ref> and image denoising <ref target="#b29" type="bibr">[29]</ref>
            <ref target="#b30" type="bibr">[30]</ref>
            <ref target="#b31" type="bibr">[31]</ref> .</s>
          <s>In particular, Zhang et al. <ref target="#b31" type="bibr">[31]</ref> have proposed a denoising convolutional neural network (DnCNN) model for removing the additive white Gaussian noise (AWGN), in which a very deep convolutional architecture is constructed while residual learning strategy and batch normalization are integrated to speed up the training process.</s>
          <s>Although the DnCNN and other CNN-based denoising models exhibit the promising denoised results, they generally involve the following problems.</s>
          <s>The training of CNN network is very complicated because it involves numerous parameters to be learned and requires too much empirical knowledge and special skills in parameter setting.</s>
          <s>In addition, most of the CNN-based denoisers are specially designed for denoising AWGN, and they cannot handle speckle noise very well.</s>
          <s>Thus, how to construct a simple and effective learning network for ultrasonic speckle reduction will pose a great challenge.</s>
        </p>
        <p>
          <s>More recently, the principal components analysis network (PCANet), a very simple unsupervised deep learning baseline introduced by Chan et al. <ref target="#b32" type="bibr">[32]</ref> , has been proposed for image classification and hand-written digit recognition.</s>
          <s>This network consists of three simple data processing components: cascaded PCA, binary hashing and blockwise histograms.</s>
          <s>In this network, the basic PCA is first employed for learning the multistage convolution kernels, and the subsequent binary hashing and the blockwise histogram are utilized to produce the output features.</s>
          <s>Compared with the CNN-based models, the training of the PCANet model is extremely simple and efficient because no any regularized parameters or numerical optimization solvers are required for the involved filter learning <ref target="#b32" type="bibr">[32]</ref> .</s>
        </p>
        <p>
          <s>Due to the advantage of the PCANet, it will be of significance to introduce this model into the NLM method to characterize structural similarity of image patches by extracting the robust intrinsic features from the ultrasound images.</s>
          <s>However, the binary hashing used in the PCANet may lead to the loss of useful feature information.</s>
          <s>To overcome the problem, we will present an improved PCANet in which an activation function Parametric Rectified Linear Unit (PReLU) <ref target="#b33" type="bibr">[33,</ref>
            <ref target="#b34" type="bibr">34]</ref> is used instead of the binary hashing and block histograms at the output stage to extract the intrinsic features.</s>
          <s>To test the restoration performance of the proposed method, the extensive experiments on the synthetic image, the simulated image and the real ultrasound images are performed to make the comparisons among the proposed method and other despeckling methods.</s>
          <s>The experimental results demonstrate the superiority of the proposed method in speckle reduction and image detail preservation.</s>
        </p>
      </div>
      <div>
        <head n="2">Methodology</head>
      </div>
      <div>
        <head n="2.1">The modified PCANet model</head>
        <p>
          <s>The PCANet model is a simple and valuable baseline for image classification and recognition tasks.</s>
          <s>The intrinsic features can be effectively extracted through three processing layers including the PCA-based convolutional layer, the binary hashing-based nonlinear layer and the histograms-based output layer.</s>
          <s>These processing methods used in the nonlinear layer and the output layer, which are similar to sparse representation strategies <ref target="#b35" type="bibr">[35,</ref>
            <ref target="#b36" type="bibr">36]</ref> , will result in the loss of image features.</s>
          <s>To overcome the disadvantage, we propose a modified PCANet, which consists of three processing components: the two convolutional layers and the output layer.</s>
          <s>The detailed structure of this network is given as follows.</s>
        </p>
        <p>
          <s>A. The convolutional layer.</s>
          <s>Let the number of training images be N, the patch size be k 1 ×k 2 at all stages.</s>
          <s>For the p-th training image, all the patches around each pixel are collected step by step.</s>
          <s>For each patch in this training image, its mean is subtracted from the intensities of all pixels in this patch.</s>
          <s>Accordingly, the mean-removed matrix A p = [a p,1 ,a p,2 ,. .</s>
          <s>.,a p,S ] is produced for the whole image, where a p,s denotes the s-th mean-removed vectorized patch, and S is the number of patches produced from the p-th image.</s>
          <s>By processing all the training images in the same way, the matrix A is obtained as:</s>
        </p>
        <formula xml:id="formula_0">A ¼ ½A 1 ; A 2 ; � � � ; A N � 2 R k 1 k 2 �SN ðEq 2Þ</formula>
        <p>
          <s>The PCA operation is then implemented on A to derive the convolution kernels.</s>
          <s>The reconstruction error within a family of orthonormal filters is minimized by the PCA algorithm, i.e.,</s>
        </p>
        <formula xml:id="formula_1">min V2R k 1 k 2 �L 1 kA À VV T Ak 2 F ; s:t: V T V ¼ I L 1 ðEq 3Þ</formula>
        <p>
          <s>where L 1 is the number of filters in the first layer, I L 1 is the identity matrix of size L 1 ×L 1 , and ||�|| F denotes the Frobenius norm.</s>
          <s>The solutions of Eq (3) are the L 1 principal eigenvectors of AA T .</s>
          <s>Therefore, the PCA filters are expressed as: from the second convolutional layer.</s>
          <s>In the original PCANet, all these L 1 ×L 2 outputs are binarized using the Heaviside step function while each group of L 2 binary outputs is weighted summed to obtain L 1 decimal-valued images.</s>
          <s>However, the previous analysis has shown that this operation will degrade the effectiveness of the extracted features.</s>
          <s>To ensure that all those features obtained from the input image can be kept as accurate as possible, the binary hashing and block histograms will be replaced by the PReLU function <ref target="#b34" type="bibr">[34]</ref> .</s>
          <s>The reason of using PReLU function instead of ReLU and sigmoid functions is that it can help to preserve image details better by additionally utilizing the structural information carried by the negative entries.</s>
          <s>In this modified PCANet model, the PReLU will be utilized as the final output layer to map nonlinearity into the data to ensure the accuracy and robustness of the extracted intrinsic features.</s>
          <s>Here, the PReLU function is defined as:</s>
        </p>
        <formula xml:id="formula_2">O 1 l ¼ mat k 1 ;k 2 ðq l ðAA T ÞÞ 2 R k 1 �k 2 ; l ¼ 1; 2; � � � ; L 1<label>ðEq</label>
        </formula>
        <formula xml:id="formula_3">PReLUðxÞ ¼ x if x &gt; 0 ax if x � 0 ðEq<label>5Þ</label>
        </formula>
        <p>
          <s>( When a = 0, the function degenerates into the Rectified Linear Unit (ReLU).</s>
          <s>If a is a very small fixed value, the PReLU will be reduced to the Leaky ReLU (LReLU).</s>
          <s>In this paper, a is fine-tuned as 0.25 to ensure the optimal despeckled results.</s>
        </p>
      </div>
      <div>
        <head n="2.2">Feature extraction using the modified PCANet model</head>
        <p>
          <s>To realize robust intrinsic features extraction, the modified PCANet must be trained to obtain the convolution filter kernels.</s>
          <s id="0" type="Dataset:Existing dataset">Considering that the PCANet uses the image patch based training strategy, we have chosen 200 general ultrasound images from the open ultrasound database [37] to train the PCANet.</s>
          <s>They consist of abdomen images, urinary tract images, pediatrics images, gynaecology images and musculo skeletal joints images, among which the number of each type of ultrasound images is 40.</s>
          <s>All the 200 images are cropped to be the size of 480×320 and pre-processed by the OBNLM filter.</s>
        </p>
        <p>
          <s id="1" type="Dataset:Existing dataset">By using the trained PCA filters, the modified PCANet can extract the intrinsic features.</s>
          <s>A flowchart is given to illustrate how the modified PCANet extracts the features from the considered patches of an input image.</s>
          <s>As shown in <ref target="#fig_1" type="figure">Fig 1,</ref> the original noisy ultrasound image is preprocessed by the OBNLM filter before input into the PCANet.</s>
          <s>The patches in the pre-processed ultrasound image are convoluted with the trained PCA filters to produce L 1 feature maps in the first convolutional layer.</s>
          <s>Then, each feature map is convoluted with the trained PCA filters to generate L 2 feature maps in the second convolutional layer.</s>
          <s>All the L 1 ×L 2 feature maps are processed by the PReLU function to produce the final outputs.</s>
        </p>
      </div>
      <div>
        <head n="2.3">The modified PCANet based nonlocal means method</head>
        <p>
          <s>The main aim in this study is to improve the despeckling performance of NLM method.</s>
          <s>To refine the calculation of structural similarity between image patches in the NLM method, the proposed where O(i,j) is the search window centered at (i,j).</s>
        </p>
        <p>
          <s>To further improve the denoised results, the structural similarity between image patches will be refined by using the image restored by the proposed method instead of the pre-filtered results produced by the OBNLM method.</s>
          <s>The refined structural similarity will help the NLM filter to provide better despeckling performance.</s>
        </p>
      </div>
      <div>
        <head n="2.4">Implementation of the proposed method</head>
        <p>
          <s>The implementation of the proposed method is summarized in <ref target="#fig_4" type="figure">Fig 3,</ref> the detailed description is as follows.</s>
        </p>
        <p>
          <s>Step 1: Pre-processing.</s>
          <s>The original noisy image is pre-filtered by the OBNLM filter to produce the pre-processed image.</s>
          <s>The noise standard deviation is estimated, and the decay parameter is set as suggested in <ref target="#b37" type="bibr">[38]</ref> .</s>
        </p>
        <p>
          <s>Step 2: Generation of the feature images.</s>
          <s>The pre-filtered image is input into the modified PCANet which has been trained using the open ultrasound database [37] to generate L 1 ×L 2 feature images as the outputs of this network.</s>
          <s>Step 3: Computation of similarity weight.</s>
          <s>For each considered image patch in the original noisy image, the corresponding feature vector is constructed by using the feature images obtained in Step 2. The produced feature vectors are employed to compute the structural similarity between two image patches via Eq (6).</s>
        </p>
        <p>
          <s>Step 4: Image restoration.</s>
          <s>Based on the similarity weight and the pre-fixed decay parameter, each pixel in the noisy image is restored by the NLM method based on Eq (7).</s>
        </p>
        <p>
          <s>Step 5: Refinement of similarity weight.</s>
          <s>The restored image obtained in Step 4 is input into the modified PCANet to produce L 1 ×L 2 feature images, and then they are used to compute the structural similarity via Eq (6).</s>
        </p>
        <p>
          <s>Step 6: Output of the final despeckled image.</s>
          <s>Based on the derived similarity weight in Step 5, the final despeckled image is produced by Eq (7).</s>
        </p>
      </div>
      <div>
        <head n="3">Experimental results and discussion</head>
        <p>
          <s>In this section, the proposed method is tested on the synthetic image, the simulated image and the real ultrasound images.</s>
          <s>To demonstrate the superiority of the proposed PCANet based NLM method (PPCA-NLM), it will be compared with such traditional well-known despeckling algorithms as Frost, Kuan, SBF, SRAD, TNLM, OBNLM and NLMLS.</s>
          <s>Meanwhile, the proposed method will be also compared with the DnCNN method and the NLM methods using the original PCANet model (OPCA-NLM), the ReLU-based PCANet model (RPCA-NLM) and the sigmoid-based PCANet model (SPCA-NLM).</s>
          <s>In all experiments, the window size of Frost and Kuan filters is fixed to be 3×3.</s>
          <s>For SBF and SRAD filters, the parameters are fine-tuned as referred in <ref target="#b9" type="bibr">[10,</ref>
            <ref target="#b10" type="bibr">11]</ref> .</s>
          <s>The sizes of similarity window and search window are set as 7×7 and 17×17 in the TNLM, OBNLM, NLMLS and PCANet based NLM filters, respectively.</s>
          <s>For the DnCNN denoiser, the same database is used as the PCANet to train the DnCNN model based on Eq (1), and the parameters and network structures are set as suggested in <ref target="#b31" type="bibr">[31]</ref> .</s>
          <s>For these NLM-based filters, the decay parameter is determined using the ruleof-thumb, i.e., h = β�σ, where β and σ denote a predefined constant and the noise standard deviation <ref target="#b37" type="bibr">[38]</ref> , respectively.</s>
          <s>In these PCANet based NLM methods, the number of PCA filters in the two convolutional layers is fixed to be 12 and the patch size is 7×7, respectively.</s>
        </p>
      </div>
      <div>
        <head n="3.1">The synthetic image</head>
        <p>
          <s>The experiment is conducted on the synthetic image corrupted by various levels of speckle noise with σ = 3, 4, 5, and 6, which is simulated based on Eq (1). is more effective in learning the different features from the noisy image, which can facilitate the accurate computation of structural similarity between image patches.</s>
        </p>
        <p>
          <s>Fig 5 presents a visual comparison of restored results for the different filters operating on the synthetic image.</s>
          <s>Obviously, speckle noise cannot be suppressed effectively by Frost and Kuan filter.</s>
          <s>In contrast, the SBF and SRAD filters perform better in noise removal, but they cause the blurring of image details.</s>
          <s>The evaluated NLM-based filters deliver sufficient speckle reduction.</s>
          <s>However, the TNLM and OBNLM filters produce the artifacts as shown in <ref type="figure">Fig 5(G)</ref> and 5(H), while the NLMLS filter damages some small image structure although it can reduce the artifacts to some extent.</s>
          <s>The DnCNN filter can facilitate enhancing the image contrast, but significant speckle noise and artifacts are observed in <ref type="figure">Fig 5(J)</ref> .</s>
          <s>For the despeckling results based on PCANet methods, one can notice that there are obvious artifacts in <ref type="figure">Fig 5(K)</ref> and 5 (L), whereas useful structure information cannot be preserved in <ref type="figure">Fig 5(M)</ref> .</s>
          <s>By comparison, the PPCA-NLM method has better performance in removing speckle noise and avoiding artifacts.</s>
          <s>The quantitative evaluations are also made among all the tested methods.</s>
          <s>Two well-known evaluation indexes as peak signal-to-noise ratio (PSNR) and structural similarity index metrics (SSIM) <ref target="#b38" type="bibr">[39]</ref> are used for performance appreciation, which are defined as:</s>
        </p>
        <formula xml:id="formula_4">PSNR</formula>
        <formula xml:id="formula_5">SSIM ¼ ð2mûm u þ C 1 Þð2dû u þ C 2 Þ ðmû 2 þ m 2 u þ C 1 Þðsû 2 þ s 2 u þ C 2 Þ ðEq<label>9Þ</label>
        </formula>
        <p>
          <s>where W and H represent the width and height of the image, respectively.</s>
          <s>u is the noise-free image andû is the denoised image.</s>
          <s>mû and μ u are the mean intensity of imagesû and u, respectively.</s>
          <s>dûu is the covariance between imagesû and u, sû and σ u are the standard deviations of imagesû and u, respectively.</s>
          <s>C 1 and C 2 are the small constants to stabilize SSIM.</s>
          <s>
            <ref target="#tab_1" type="table">Tables 1 and 2</ref> list the PSNR and SSIM values for all evaluated methods operating on the synthetic image corrupted with different levels of speckle noise, where the best values are marked in bold.</s>
          <s>It can be seen that the DnCNN can produce the maximum PSNR at all noise levels, and the PPCA-NLM method ranks the second.</s>
          <s>However, the proposed method provides significantly higher SSIM values than the DnCNN.</s>
          <s>The overall evaluation based on the abovementioned visual inspection and the objective indexes demonstrates that the PPCA-NLM method exhibits the excellent despeckling performance for the synthetic image.</s>
        </p>
      </div>
      <div>
        <head n="3.2">The simulated image</head>
        <p>
          <s>A more challenging and relevant ultrasound image has been generated for the "cyst" phantom based on FieldⅡ simulation, which is a program to simulate ultrasound transducer fields and ultrasound imaging using the linear acoustics.</s>
          <s>The "cyst" phantom consists of a collection of point targets, five cyst regions, and five highly scattering regions <ref type="bibr">[40]</ref> .</s>
          <s>
            <ref target="#fig_8" type="figure">Fig 7 presents</ref> the "cyst" phantom, the simulated image, and the despeckled results of all the tested methods.</s>
          <s>The Frost, Kuan and SBF filters keep much noise in the images as shown in <ref target="#fig_8" type="figure">Fig 7(C)-7(E)</ref> .</s>
          <s>The SRAD filter performs well in noise removal, but it leads to the blurry edges and the staircase effect in the despeckled image.</s>
          <s>All NLM-based methods smooth out speckle noise more effectively than the above-mentioned local filters.</s>
          <s>However, the TNLM and NLMLS filters cannot maintain the sharpness of point targets and the OBNLM method produces the obvious artifacts.</s>
          <s>For the DnCNN method, many unwanted artifacts can be observed in the smooth region as shown in <ref target="#fig_8" type="figure">Fig 7(J)</ref> .</s>
          <s>
            <ref target="#fig_8" type="figure">From Fig 7(</ref> K)-7(M), one can see that the OPCA-NLM and RPCA-NLM filters tend to retain speckle noise, while the SPCA-NLM filter produces an over-smoothed image.</s>
          <s>The comparison with the other eleven methods shows that the PPCA-NLM method can smooth out speckle noise well while providing the clearer boundaries of points as depicted in <ref target="#fig_8" type="figure">Fig 7(N)</ref> .</s>
          <s>Moreover, two other widely used evaluation indexes, i.e., equivalent number of looks (ENL) and contrast-to-noise ratio (CNR) <ref target="#b39" type="bibr">[41]</ref> are utilized to quantitatively appreciate the despeckling performance, which are defined as:</s>
        </p>
        <formula xml:id="formula_6">ENL ¼ m 2 b s 2 b ðEq 10Þ CNR ¼ jm b À m o j ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi s 2 b þ s 2 o p ðEq 11Þ</formula>
        <p>
          <s>where μ b and μ o are the mean intensity of background area and object area, σ b and σ o are the standard deviation of background area and object area, respectively.</s>
          <s>Four pairs of ROIs are selected to evaluate the despeckling performance for these tested methods, and the ROIs are marked with different colors as shown in <ref target="#fig_8" type="figure">Fig 7(B)</ref> .</s>
          <s>The ENL and CNR are listed in <ref target="#tab_3" type="table">Tables 3 and 4</ref> , respectively.</s>
          <s>As regards ENL, the PPCA-NLM method provides the maximum values at all ROIs.</s>
          <s>Likewise, the proposed method performs the best for three ROIs except that its CNR is slightly less than that of the RPCA-NLM method for the blue ROI.</s>
          <s>The performance appreciation based on ENL and CNR confirms that the PPCA-NLM method is superior to other compared methods.</s>
        </p>
      </div>
      <div>
        <head n="3.3">The real ultrasound images</head>
        <p>
          <s>Three real ultrasound images are also used to further assess the effectiveness of the proposed method.</s>
          <s>
            <ref target="#fig_9" type="figure">Fig 8 shows</ref> the despeckled results for the compared methods on a real ultrasound image of benign lymph nodes.</s>
          <s>Visually, the Frost and Kuan filters maintain much speckle in the image as shown in <ref target="#fig_9" type="figure">Fig 8(B)</ref> and 8(C), while the SBF and SRAD filters result in the blurry object boundaries as shown in <ref target="#fig_9" type="figure">Fig 8(D) and 8(E)</ref> .</s>
          <s>Compared with the TNLM and NLMLS filters, the PCANet based NLM filters are more effective in smoothing out speckle noise.</s>
          <s>
            <ref target="#tab_4" type="table">Tables 5 and 6</ref> .</s>
          <s>With regard to ENL results, the PPCA-NLM method produces the maximum values at three ROIs among all the filters.</s>
          <s>In terms of CNR, the OPCA-NLM method provides the competitive results, followed by the PPCA-NLM and DnCNN methods.</s>
          <s>The above quantitative comparisons and visual inspection illustrate that the PPCA-NLM method is very suitable and practicable for despeckling the real ultrasound image.</s>
        </p>
        <p>
          <s>Besides, two other clinical ultrasound images including the fetal image and the parotid gland image are used to further display the visual impression for the TNLM, OBNLM, NLMLS, DnCNN and PPCA-NLM filters.</s>
          <s>As indicated in <ref target="#fig_10" type="figure">Figs 9</ref> and 10, the PPCA-NLM method outperforms the compared methods in that it not only effectively removes speckle noise but also enhances the sharpness of boundaries and retains image structures very well.</s>
        </p>
      </div>
      <div>
        <head n="4">Conclusion</head>
        <p>
          <s>In this paper, the modified PCANet based deep learning baseline is introduced into NLM method for reducing speckle noise in the ultrasound images.</s>
          <s>This proposed method utilizes the intrinsic features extracted from an input noisy image by the PCANet to refine the similarity computation in the NLM method.</s>
          <s>The introduction of the intrinsic features instead of the gray-level information into the NLM method can facilitate the effective despeckling of ultrasound images due to its effectiveness in representing their structural information.</s>
          <s>The experimental results demonstrate that the proposed method outperforms the other compared methods in speckle reduction and image detail preservation.</s>
          <s>Therefore, the proposed approach has the great potential application to ultrasound-based clinical diagnosis.</s>
          <s>In future, the new deep learning models will be developed to denoise the images corrupted by Rician noise or Poisson noise.</s>
        </p>
      </div>
      <div>
        <head>Author Contributions</head>
        <p>
          <s>Conceptualization: Houqiang Yu, Mingyue Ding, Xuming Zhang.</s>
        </p>
      </div>
      <figure xml:id="fig_0">
        <head/>
        <label/>
        <figDesc>4Þ where q l (AA T ) represents the l-th principal eigenvector of AA T , and mat k 1 ;k 2 ðq l ðAA T ÞÞ is the function that maps q l (AA T ) to the matrix O 1 l . Similar to the deep neural networks (DNNs), the multiple stages of PCA filters can be stacked for extracting higher level features. All outputs of the first convolutional layer are uti- lized as the inputs of the second convolutional layer. By repeating almost the same process as in the first convolutional layer, the leading L 2 eigenvectors are obtained as the filters in the sec- ond one. B. The output layer. For the p-th training image, there are L 1 outputs fF</figDesc>
      </figure>
      <figure xml:id="fig_1">
        <head>Fig 1 .</head>
        <label>1</label>
        <figDesc>Fig 1. Illustration of feature extraction of image patches using the modified PCANet. https://doi.org/10.1371/journal.pone.0205390.g001</figDesc>
      </figure>
      <figure xml:id="fig_2">
        <head>Fig 2 .</head>
        <label>2</label>
        <figDesc>Fig 2. A detailed illustration of the construction of feature vectors based on the feature patches. https://doi.org/10.1371/journal.pone.0205390.g002</figDesc>
      </figure>
      <figure xml:id="fig_3">
        <head/>
        <label/>
        <figDesc>Fig 4 shows the learned feature images by different activation functions based PCANet on the synthetic image with σ = 3. It can be seen from Fig 4 that the PReLU based PCANet model</figDesc>
      </figure>
      <figure xml:id="fig_4">
        <head>Fig 3 .</head>
        <label>3</label>
        <figDesc>Fig 3. The scheme of the proposed method. https://doi.org/10.1371/journal.pone.0205390.g003</figDesc>
      </figure>
      <figure xml:id="fig_5">
        <head/>
        <label/>
        <figDesc>Furthermore, the zoomed views of a region of interest (ROI) from Fig 5 are shown in Fig 6 to demonstrate the advantage of the proposed method in preserving the small structures and edges. Clearly, Fig 6(C)-6(G) obtained with the Frost, Kuan, SBF, SRAD, and TNLM filters are unsatisfac- tory since these methods cannot provide good edge preservation. In Fig 6(H)-6(J), it can be seen that the OBNLM and NLMLS methods blur the edges and details of the rectangle, lines and circular point, while the DnCNN denoiser tends to distort the small structures and produce the obvious artifacts in the smooth region. Similarly, one can see from Fig 6(K)-6(M) that the OPCA-NLM and RPCA-NLM filters generate the blurred edges, while the SPCA-NLM filter causes serious damage to the image details. Compared with the other evaluated filters, the PPCA-NLM method is the most effective for preserving the fine structures and maintaining the edge sharpness in the image.</figDesc>
      </figure>
      <figure xml:id="fig_6">
        <head>Fig 4 . g004 Fig 5 .</head>
        <label>4g0045</label>
        <figDesc>Fig 4. Comparisons of the learned feature images by various activation functions in the PCANet. The top row, the second row, the third row and the bottom row show the learned feature images by the original PCANet, ReLU-based PCANet, sigmoid-based PCANet and PReLU-based PCANet models, respectively. https://doi.org/10.1371/journal.pone.0205390.g004</figDesc>
      </figure>
      <figure xml:id="fig_7">
        <head>Fig 6 .</head>
        <label>6</label>
        <figDesc>Fig 6. Comparison of zoomed details in Fig 5 for the twelve despeckling methods. (a) Original ROI, (b) Noisy ROI, (c) Frost filter, (d) Kuan filter, (e) SBF filter, (f) SRAD filter, (g) TNLM filter, (h) OBNLM filter, (i) NLMLS filter, (j) DnCNN filter, (k) OPCA-NLM filter, (l) RPCA-NLM filter, (m) SPCA-NLM filter, and (n) PPCA-NLM filter. https://doi.org/10.1371/journal.pone.0205390.g006</figDesc>
      </figure>
      <figure xml:id="fig_8">
        <head>Fig 7 .</head>
        <label>7</label>
        <figDesc>Fig 7. Visual comparison of restoration performance of various despeckling methods on the simulated image. (a) the "cyst" phantom, (b) simulated image generated by FieldⅡ and four ROIs marked with various colors, (c) Frost filter, (d) Kuan filter, (e) SBF filter, (f) SRAD filter, (g) TNLM filter, (h) OBNLM filter, (i) NLMLS filter, (j) DnCNN filter, (k) OPCA-NLM filter, (l) RPCA-NLM filter, (m) SPCA-NLM filter, and (n) PPCA-NLM filter.</figDesc>
      </figure>
      <figure xml:id="fig_9">
        <head>Fig 8 .</head>
        <label>8</label>
        <figDesc>Fig 8. Comparison of restoration performance of various despeckling methods on a real ultrasound image of benign lymph nodes. (a) original noisy image and four ROIs marked with the different colors, (b) Frost filter, (c) Kuan filter, (d) SBF filter, (e) SRAD filter, (f) TNLM filter, (g) OBNLM filter, (h) NLMLS filter, (i) DnCNN filter, (j) OPCA-NLM filter, (k) RPCA-NLM filter, (l) SPCA-NLM filter, and (m) PPCA-NLM filter.</figDesc>
      </figure>
      <figure xml:id="fig_10">
        <head>Fig 9 .</head>
        <label>9</label>
        <figDesc>Fig 9. Comparison of restoration performance on a real fetal ultrasound image for the NLM-based and DnCNN methods. (a) original image, (b) TNLM filter, (c) OBNLM filter, (d) NLMLS filter, (e) DnCNN filter, and (f) PPCA-NLM filter. https://doi.org/10.1371/journal.pone.0205390.g009</figDesc>
      </figure>
      <figure type="table" validated="false" xml:id="tab_0">
        <head>as :</head>
        <label>as</label>
        <figDesc>uðx; yÞ ¼ vðx; yÞ þ vðx; yÞ g Zðx; yÞ ðEq 1Þ</figDesc>
        <table/>
      </figure>
      <figure type="table" validated="true" xml:id="tab_1">
        <head>Table 1 .</head>
        <label>1</label>
        <figDesc>The PSNR (dB) values of various despeckling methods on the synthetic image.</figDesc>
        <table>Methods 
σ = 3 
σ = 4 
σ = 5 
σ = 6 

Noisy image 
16.60 
14.45 
12.87 
11.73 

Frost 
22.25 
20.11 
18.55 
17.42 

Kuan 
26.03 
23.79 
22.11 
20.99 

SBF 
27.23 
25.88 
24.72 
23.95 

SRAD 
30.51 
27.20 
22.70 
19.47 

TNLM 
29.96 
27.70 
26.28 
25.12 

OBNLM 
30.50 
28.44 
27.26 
26.24 

NLMLS 
30.96 
28.91 
27.70 
26.50 

DnCNN 
32.98 
31.03 
30.20 
28.70 

OPCA-NLM 
32.46 
29.87 
27.93 
26.48 

RPCA-NLM 
32.59 
30.30 
28.54 
27.10 

SPCA-NLM 
26.17 
25.97 
25.78 
25.39 

PPCA-NLM 
32.98 
30.79 
29.30 
27.71 

https://doi.org/10.1371/journal.pone.0205390.t001 </table>
      </figure>
      <figure type="table" validated="true" xml:id="tab_2">
        <head>Table 2 .</head>
        <label>2</label>
        <figDesc>The SSIM values of various despeckling methods on the synthetic image.</figDesc>
        <table>Methods 
σ = 3 
σ = 4 
σ = 5 
σ = 6 

Noisy image 
0.105 
0.071 
0.054 
0.042 

Frost 
0.254 
0.185 
0.146 
0.119 

Kuan 
0.441 
0.336 
0.270 
0.228 

SBF 
0.649 
0.583 
0.504 
0.467 

SRAD 
0.863 
0.698 
0.415 
0.219 

TNLM 
0.708 
0.601 
0.519 
0.456 

OBNLM 
0.791 
0.717 
0.666 
0.640 

NLMLS 
0.926 
0.894 
0.869 
0.852 

DnCNN 
0.903 
0.857 
0.840 
0.742 

OPCA-NLM 
0.927 
0.851 
0.751 
0.703 

RPCA-NLM 
0.936 
0.892 
0.831 
0.800 

SPCA-NLM 
0.830 
0.829 
0.828 
0.818 

PPCA-NLM 
0.950 
0.928 
0.904 
0.879 

https://doi.org/10.1371/journal.pone.0205390.t002 </table>
      </figure>
      <figure type="table" validated="false" xml:id="tab_3">
        <head>Table 3 .</head>
        <label>3</label>
        <figDesc>The ENL values of four ROIs on the simulated ultrasound image.https://doi.org/10.1371/journal.pone.0205390.t003 Table 4. The CNR values of four ROIs on the simulated ultrasound image.https://doi.org/10.1371/journal.pone.0205390.t004</figDesc>
        <table>Methods 
ROI 1 (blue) 
ROI 2 (green) 
ROI 3 (yellow) 
ROI 4 (red) 

Noisy image 
30.49 
30.54 
35.77 
29.02 

Frost 
44.64 
40.83 
49.43 
44.46 

Kuan 
49.10 
43.82 
54.18 
50.10 

SBF 
88.05 
63.55 
120.95 
170.36 

SRAD 
175.44 
125.91 
286.10 
168.68 

TNLM 
148.97 
162.10 
186.82 
185.09 

OBNLM 
282.94 
439.41 
417.05 
483.60 

NLMLS 
279.34 
510.83 
430.73 
529.97 

DnCNN 
160.93 
550.15 
449.86 
800.90 

OPCA-NLM 
414.09 
522.25 
623.68 
702.50 

RPCA-NLM 
520.27 
595.68 
935.03 
850.07 

SPCA-NLM 
464.00 
1110.27 
1125.99 
783.06 

PPCA-NLM 
546.77 
1336.78 
1163.53 
1145.27 

</table>
      </figure>
      <figure type="table" validated="false" xml:id="tab_4">
        <head>Table 5 .</head>
        <label>5</label>
        <figDesc>The ENL values of four ROIs on a real ultrasound image.https://doi.org/10.1371/journal.pone.0205390.t005</figDesc>
        <table>Methods 
ROI 1 (blue) 
ROI 2 (green) 
ROI 3 (yellow) 
ROI 4 (red) 

Noisy image 
219.45 
338.21 
112.34 
102.96 

Frost 
333.15 
569.40 
172.76 
136.67 

Kuan 
358.50 
635.66 
184.73 
146.96 

SBF 
536.42 
1155.25 
245.41 
153.03 

SRAD 
564.67 
1145.40 
292.45 
193.45 

TNLM 
926.57 
2204.59 
243.73 
191.82 

OBNLM 
1564.69 
5393.52 
591.38 
396.95 

NLMLS 
1167.61 
5212.99 
391.28 
290.55 

DnCNN 
1457.50 
1419.98 
534.73 
538.04 

OPCA-NLM 
2913.80 
6073.30 
673.99 
426.89 

RPCA-NLM 
2476.94 
6232.09 
687.21 
487.45 

SPCA-NLM 
1857.40 
413.23 
666.11 
282.31 

PPCA-NLM 
2054.56 
8175.66 
845.83 
935.00 

</table>
      </figure>
      <figure type="table" validated="false" xml:id="tab_5">
        <head>Table 6 .</head>
        <label>6</label>
        <figDesc>The CNR values of four ROIs on a real ultrasound image.https://doi.org/10.1371/journal.pone.0205390.t006</figDesc>
        <table>Methods 
ROI 1 (blue) 
ROI 2 (green) 
ROI 3 (yellow) 
ROI 4 (red) 

Noisy image 
9.28 
11.79 
5.45 
3.80 

Frost 
10.56 
14.15 
6.39 
4.18 

Kuan 
10.71 
15.04 
6.51 
4.27 

SBF 
12.63 
17.52 
7.27 
4.38 

SRAD 
11.46 
16.01 
7.41 
4.43 

TNLM 
15.83 
19.90 
7.36 
4.79 

OBNLM 
18.29 
21.53 
9.78 
6.21 

NLMLS 
14.65 
20.97 
8.32 
5.44 

DnCNN 
16.88 
18.01 
11.00 
5.12 

OPCA-NLM 
19.86 
21.88 
10.16 
6.58 

RPCA-NLM 
19.45 
21.22 
10.08 
6.67 

SPCA-NLM 
18.96 
8.15 
6.12 
1.91 

PPCA-NLM 
19.42 
21.80 
10.33 
7.13 

</table>
      </figure>
      <figure type="table" validated="false" xml:id="tab_6">
        <head/>
        <label/>
        <figDesc>Data curation: Houqiang Yu, Xuming Zhang. Formal analysis: Xuming Zhang, Jinbo Wu.acquisition: Xuming Zhang. Investigation: Houqiang Yu, Xuming Zhang. Methodology: Houqiang Yu, Xuming Zhang, Jinbo Wu. Resources: Mingyue Ding. Software: Houqiang Yu, Xuming Zhang, Jinbo Wu.</figDesc>
        <table>Funding </table>
      </figure>
      <note place="foot">PLOS ONE | https://doi.org/10.1371/journal.pone.0205390 October 12, 2018</note>
      <note place="foot">https://doi.org/10.1371/journal.pone.0205390.g005 PCANet based NLM method for ultrasonic speckle removal PLOS ONE | https://doi.org/10.1371/journal.pone.0205390 October 12, 2018 9 / 19</note>
      <note place="foot">https://doi.org/10.1371/journal.pone.0205390.g007 PCANet based NLM method for ultrasonic speckle removal PLOS ONE | https://doi.org/10.1371/journal.pone.0205390 October 12, 2018 12 / 19</note>
      <note place="foot">https://doi.org/10.1371/journal.pone.0205390.g008 PCANet based NLM method for ultrasonic speckle removal PLOS ONE | https://doi.org/10.1371/journal.pone.0205390 October 12, 2018</note>
      <note place="foot">PLOS ONE | https://doi.org/10.1371/journal.pone.0205390 October 12, 2018 16 / 19</note>
    </body>
    <back>
      <div type="acknowledgement">
        <div>
          <p>
            <s>Supervision: Xuming Zhang.</s>
          </p>
        </div>
        <div>
          <head>Writing -original draft: Houqiang Yu.</head>
          <p>
            <s>Writing -review &amp; editing: Houqiang Yu, Xuming Zhang.</s>
          </p>
        </div>
      </div>
      <div type="references">
        <listBibl>
          <biblStruct xml:id="b0">
            <analytic>
              <title level="a" type="main">Nonlinear diffusion in Laplacian pyramid domain for ultrasonic speckle reduction</title>
              <author>
                <persName>
                  <forename type="first">F</forename>
                  <surname>Zhang</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">Y M</forename>
                  <surname>Yoo</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">L M</forename>
                  <surname>Koh</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">Y</forename>
                  <surname>Kim</surname>
                </persName>
              </author>
              <idno type="doi">10.1109/TMI.2006.889735</idno>
              <ptr target="https://doi.org/10.1109/TMI.2006.889735PMID"/>
            </analytic>
            <monogr>
              <title level="j">IEEE Transactions on Medical Imaging</title>
              <imprint>
                <biblScope unit="volume">26</biblScope>
                <biblScope unit="issue">2</biblScope>
                <biblScope unit="page">17304734</biblScope>
                <date type="published" when="2007"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b1">
            <analytic>
              <title level="a" type="main">Ultrasound-specific segmentation via decorrelation and statistical region-based active contours</title>
              <author>
                <persName>
                  <forename type="first">G</forename>
                  <surname>Slabaugh</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">G</forename>
                  <surname>Unal</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">T</forename>
                  <surname>Fang</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">M</forename>
                  <surname>Wels</surname>
                </persName>
              </author>
              <idno type="doi">10.1109/CVPR.2006.318</idno>
              <ptr target="https://doi.org/10.1109/CVPR.2006.318"/>
            </analytic>
            <monogr>
              <title level="m">2006 IEEE Conference on Computer Vision and Pattern Recognition</title>
              <imprint>
                <date type="published" when="2006"/>
                <biblScope from="45" to="53" unit="page"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b2">
            <analytic>
              <title level="a" type="main">Evaluation of four probability distribution models for speckle in clinical cardiac ultrasound images</title>
              <author>
                <persName>
                  <forename type="first">Z</forename>
                  <surname>Tao</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">H D</forename>
                  <surname>Tagare</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">J</forename>
                  <surname>Beaty</surname>
                </persName>
              </author>
              <idno type="doi">10.1109/TMI.2006.881376</idno>
              <ptr target="https://doi.org/10.1109/TMI.2006.881376PMID"/>
            </analytic>
            <monogr>
              <title level="j">IEEE Transactions on Medical Imaging</title>
              <imprint>
                <biblScope unit="volume">25</biblScope>
                <biblScope unit="issue">11</biblScope>
                <biblScope unit="page">17117777</biblScope>
                <date type="published" when="2006"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b3">
            <analytic>
              <title level="a" type="main">Nonlocal means-based speckle filtering for ultrasound images</title>
              <author>
                <persName>
                  <forename type="first">P</forename>
                  <surname>Coupe</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">P</forename>
                  <surname>Hellier</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">C</forename>
                  <surname>Kervrann</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">C</forename>
                  <surname>Barillot</surname>
                </persName>
              </author>
              <idno type="doi">10.1109/TIP.2009.2024064</idno>
              <ptr target="https://doi.org/10.1109/TIP.2009.2024064PMID"/>
            </analytic>
            <monogr>
              <title level="j">IEEE Transactions on Image Processing</title>
              <imprint>
                <biblScope unit="volume">18</biblScope>
                <biblScope unit="issue">10</biblScope>
                <biblScope unit="page">19482578</biblScope>
                <date type="published" when="2009"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b4">
            <analytic>
              <title level="a" type="main">Nonlocal means method using weight refining for despeckling of ultrasound images</title>
              <author>
                <persName>
                  <forename type="first">Y</forename>
                  <surname>Zhan</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">M</forename>
                  <surname>Ding</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">L</forename>
                  <surname>Wu</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">X</forename>
                  <surname>Zhang</surname>
                </persName>
              </author>
              <idno type="doi">10.1016/j.sigpro.2013.12.019</idno>
              <ptr target="https://doi.org/10.1016/j.sigpro.2013.12.019"/>
            </analytic>
            <monogr>
              <title level="j">Signal Processing</title>
              <imprint>
                <biblScope unit="volume">103</biblScope>
                <biblScope from="201" to="213" unit="page"/>
                <date type="published" when="2014"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b5">
            <analytic>
              <title level="a" type="main">An adaptive weighted median filter for speckle suppression in medical ultrasonic images</title>
              <author>
                <persName>
                  <forename type="first">T</forename>
                  <surname>Loupas</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">W N</forename>
                  <surname>Mcdicken</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">Allan</forename>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">P</forename>
                  <forename type="middle">L</forename>
                </persName>
              </author>
              <idno type="doi">10.1109/31.16577</idno>
              <ptr target="https://doi.org/10.1109/31.16577"/>
            </analytic>
            <monogr>
              <title level="j">IEEE Transactions on Circuits and Systems</title>
              <imprint>
                <biblScope unit="volume">36</biblScope>
                <biblScope unit="issue">1</biblScope>
                <biblScope from="129" to="135" unit="page"/>
                <date type="published" when="1989"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b6">
            <analytic>
              <title level="a" type="main">Review of speckle noise reduction techniques for ultrasound imaging</title>
              <author>
                <persName>
                  <forename type="first">A</forename>
                  <surname>Kaur</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">S</forename>
                  <forename type="middle">K</forename>
                  <surname>Ranade</surname>
                </persName>
              </author>
            </analytic>
            <monogr>
              <title level="j">Imperial Journal of Interdisciplinary Research</title>
              <imprint>
                <biblScope unit="volume">2</biblScope>
                <biblScope unit="issue">9</biblScope>
                <biblScope from="29" to="35" unit="page"/>
                <date type="published" when="2016"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b7">
            <analytic>
              <title level="a" type="main">A model for radar images and its application to adaptive digital filtering of multiplicative noise</title>
              <author>
                <persName>
                  <forename type="first">V S</forename>
                  <surname>Frost</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">J A</forename>
                  <surname>Stiles</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">K S</forename>
                  <surname>Shanmugan</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">J</forename>
                  <forename type="middle">C</forename>
                  <surname>Holtzman</surname>
                </persName>
              </author>
              <idno type="doi">10.1109/TPAMI.1982.4767223</idno>
              <ptr target="http://doi.org/10.1109/TPAMI.1982.4767223PMID"/>
            </analytic>
            <monogr>
              <title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
              <imprint>
                <biblScope unit="volume">4</biblScope>
                <biblScope unit="issue">2</biblScope>
                <biblScope unit="page">21869022</biblScope>
                <date type="published" when="1982"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b8">
            <analytic>
              <title level="a" type="main">Adaptive restoration of images with speckle</title>
              <author>
                <persName>
                  <forename type="first">D</forename>
                  <surname>Kuan</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">A</forename>
                  <surname>Sawchuk</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">T</forename>
                  <surname>Strand</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">P</forename>
                  <surname>Chavel</surname>
                </persName>
              </author>
              <idno type="doi">10.1109/TASSP.1987.1165131</idno>
              <ptr target="https://doi.org/10.1109/TASSP.1987.1165131"/>
            </analytic>
            <monogr>
              <title level="j">IEEE Transactions on Acoustics, Speech, and Signal Processing</title>
              <imprint>
                <biblScope unit="volume">35</biblScope>
                <biblScope unit="issue">3</biblScope>
                <biblScope from="373" to="383" unit="page"/>
                <date type="published" when="1987"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b9">
            <analytic>
              <title level="a" type="main">Ultrasound despeckling for contrast enhancement</title>
              <author>
                <persName>
                  <forename type="first">P C</forename>
                  <surname>Tay</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">C D</forename>
                  <surname>Garson</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">S T</forename>
                  <surname>Acton</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">J</forename>
                  <surname>Hossack</surname>
                </persName>
              </author>
              <idno type="doi">10.1109/TIP.2010.2044962</idno>
              <ptr target="https://doi.org/10.1109/TIP.2010.2044962PMID"/>
            </analytic>
            <monogr>
              <title level="j">IEEE Transactions on Image Processing</title>
              <imprint>
                <biblScope unit="volume">19</biblScope>
                <biblScope unit="issue">7</biblScope>
                <biblScope unit="page">20227984</biblScope>
                <date type="published" when="2010"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b10">
            <analytic>
              <title level="a" type="main">Speckle reducing anisotropic diffusion</title>
              <author>
                <persName>
                  <forename type="first">Y</forename>
                  <surname>Yu</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">S</forename>
                  <forename type="middle">T</forename>
                  <surname>Acton</surname>
                </persName>
              </author>
              <idno type="doi">10.1109/TIP.2002.804276</idno>
              <ptr target="https://doi.org/10.1109/TIP.2002.804276PMID"/>
            </analytic>
            <monogr>
              <title level="j">IEEE Transactions on Image Processing</title>
              <imprint>
                <biblScope unit="volume">11</biblScope>
                <biblScope unit="issue">11</biblScope>
                <biblScope unit="page">18249696</biblScope>
                <date type="published" when="2002"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b11">
            <analytic>
              <title level="a" type="main">Noise adaptive wavelet thresholding for speckle noise removal in optical coherence tomography</title>
              <author>
                <persName>
                  <forename type="first">F</forename>
                  <surname>Zaki</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">Y</forename>
                  <surname>Wang</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">H</forename>
                  <surname>Su</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">X</forename>
                  <surname>Yuan</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">X</forename>
                  <surname>Liu</surname>
                </persName>
              </author>
              <idno type="doi">10.1364/BOE.8.002720</idno>
              <ptr target="https://doi.org/10.1364/BOE.8.002720PMID"/>
            </analytic>
            <monogr>
              <title level="j">Biomedical Optics Express</title>
              <imprint>
                <biblScope unit="volume">8</biblScope>
                <biblScope unit="issue">5</biblScope>
                <biblScope unit="page">28663901</biblScope>
                <date type="published" when="2017"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b12">
            <analytic>
              <title level="a" type="main">A versatile wavelet domain noise filtration technique for medical imaging</title>
              <author>
                <persName>
                  <forename type="first">A</forename>
                  <surname>Pizurica</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">W</forename>
                  <surname>Philips</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">I</forename>
                  <surname>Lemahieu</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">M</forename>
                  <surname>Acheroy</surname>
                </persName>
              </author>
              <idno type="doi">10.1109/TMI.2003.809588</idno>
              <ptr target="https://doi.org/10.1109/TMI.2003.809588PMID"/>
            </analytic>
            <monogr>
              <title level="j">IEEE Transactions on Medical Imaging</title>
              <imprint>
                <biblScope unit="volume">22</biblScope>
                <biblScope unit="issue">3</biblScope>
                <biblScope unit="page">12760550</biblScope>
                <date type="published" when="2003"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b13">
            <analytic>
              <title level="a" type="main">Speckle noise reduction in ultrasound images by wavelet thresholding based on subband mean difference</title>
              <author>
                <persName>
                  <forename type="first">M M</forename>
                  <surname>Rahman</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">M</forename>
                  <surname>Azim</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <surname>Mina</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">S</forename>
                  <surname>Uddin</surname>
                </persName>
              </author>
            </analytic>
            <monogr>
              <title level="j">International Journal of Tomography and Statistics</title>
              <imprint>
                <biblScope unit="volume">20</biblScope>
                <biblScope unit="issue">2</biblScope>
                <biblScope from="91" to="97" unit="page"/>
                <date type="published" when="2012"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b14">
            <analytic>
              <title level="a" type="main">A non-local algorithm for image denoising</title>
              <author>
                <persName>
                  <forename type="first">A</forename>
                  <surname>Buades</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">B</forename>
                  <surname>Coll</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">J</forename>
                  <surname>Morel</surname>
                </persName>
              </author>
              <idno type="doi">10.1109/CVPR.2005.38</idno>
              <ptr target="http://doi.org/10.1109/CVPR.2005.38"/>
            </analytic>
            <monogr>
              <title level="m">2005 IEEE Conference on Computer Vision and Pattern Recognition</title>
              <imprint>
                <date type="published" when="2005"/>
                <biblScope from="60" to="65" unit="page"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b15">
            <analytic>
              <title level="a" type="main">Invariant moments and transform-based unbiased nonlocal means for denoising of MR images</title>
              <author>
                <persName>
                  <forename type="first">C</forename>
                  <surname>Singh</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">Ranade</forename>
                  <forename type="middle">S K</forename>
                  <surname>Singh</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">K</forename>
                </persName>
              </author>
              <idno type="doi">10.1016/j.bspc.2016.05.007</idno>
              <ptr target="https://doi.org/10.1016/j.bspc.2016.05.007"/>
            </analytic>
            <monogr>
              <title level="j">Biomedical Signal Processing and Control</title>
              <imprint>
                <biblScope unit="volume">30</biblScope>
                <biblScope from="13" to="24" unit="page"/>
                <date type="published" when="2016"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b16">
            <analytic>
              <title level="a" type="main">Spectral CT image restoration via an average image-induced nonlocal means filter</title>
              <author>
                <persName>
                  <forename type="first">D</forename>
                  <surname>Zeng</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">J</forename>
                  <surname>Huang</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">H</forename>
                  <surname>Zhang</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">Z</forename>
                  <surname>Bian</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">S</forename>
                  <surname>Niu</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">Z</forename>
                  <surname>Zhang</surname>
                </persName>
              </author>
              <idno type="doi">10.1109/TBME.2015.2476371</idno>
              <ptr target="https://doi.org/10.1109/TBME.2015.2476371PMID"/>
            </analytic>
            <monogr>
              <title level="j">IEEE Transactions on Biomedical Engineering</title>
              <imprint>
                <biblScope unit="volume">63</biblScope>
                <biblScope unit="issue">5</biblScope>
                <biblScope unit="page">26353358</biblScope>
                <date type="published" when="2016"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b17">
            <analytic>
              <title level="a" type="main">Denoising MR images using non-local means filter with combined patch and pixel similarity</title>
              <author>
                <persName>
                  <forename type="first">X</forename>
                  <surname>Zhang</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">G</forename>
                  <surname>Hou</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">J</forename>
                  <surname>Ma</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">W</forename>
                  <surname>Yang</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">B</forename>
                  <surname>Lin</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">Y</forename>
                  <surname>Xu</surname>
                </persName>
              </author>
              <idno type="doi">10.1371/journal.pone.0100240</idno>
              <ptr target="https://doi.org/10.1371/journal.pone.0100240PMID"/>
            </analytic>
            <monogr>
              <title level="j">PloS ONE</title>
              <imprint>
                <biblScope unit="volume">9</biblScope>
                <biblScope unit="issue">6</biblScope>
                <biblScope unit="page">24933024</biblScope>
                <date type="published" when="2014"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b18">
            <analytic>
              <title level="a" type="main">Nonlocal means-based speckle filtering for ultrasound images</title>
              <author>
                <persName>
                  <forename type="first">P</forename>
                  <surname>Coupe</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">P</forename>
                  <surname>Hellier</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">C</forename>
                  <surname>Kervrann</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">C</forename>
                  <surname>Barillot</surname>
                </persName>
              </author>
              <idno type="doi">10.1109/TIP.2009.2024064</idno>
              <ptr target="https://doi.org/10.1109/TIP.2009.2024064PMID"/>
            </analytic>
            <monogr>
              <title level="j">IEEE Transactions on Image Processing</title>
              <imprint>
                <biblScope unit="volume">18</biblScope>
                <biblScope unit="issue">10</biblScope>
                <biblScope unit="page">19482578</biblScope>
                <date type="published" when="2009"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b19">
            <analytic>
              <title level="a" type="main">Nonlocal total-variation-based speckle filtering for ultrasound images</title>
              <author>
                <persName>
                  <forename type="first">T</forename>
                  <surname>Wen</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">J</forename>
                  <surname>Gu</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">L</forename>
                  <surname>Li</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">W</forename>
                  <surname>Qin</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">L</forename>
                  <surname>Wang</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">Y</forename>
                  <surname>Xie</surname>
                </persName>
              </author>
              <idno type="doi">10.1177/0161734615600676</idno>
              <ptr target="https://doi.org/10.1177/0161734615600676PMID:26316172"/>
            </analytic>
            <monogr>
              <title level="j">Ultrasonic Imaging</title>
              <imprint>
                <biblScope unit="volume">38</biblScope>
                <biblScope unit="issue">4</biblScope>
                <biblScope from="254" to="275" unit="page"/>
                <date type="published" when="2015"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b20">
            <analytic>
              <title level="a" type="main">Local statistics and non-local mean filter for speckle noise reduction in medical ultrasound image</title>
              <author>
                <persName>
                  <forename type="first">J</forename>
                  <surname>Yang</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">J</forename>
                  <surname>Fan</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">Ai</forename>
                  <forename type="middle">D</forename>
                  <surname>Wang</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">X</forename>
                  <surname>Zheng</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">Y</forename>
                  <surname>Tang</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">S</forename>
                </persName>
              </author>
              <idno type="doi">10.1016/j.neucom.2015.05.140</idno>
              <ptr target="https://doi.org/10.1016/j.neucom.2015.05.140"/>
            </analytic>
            <monogr>
              <title level="j">Neurocomputing</title>
              <imprint>
                <biblScope unit="volume">195</biblScope>
                <biblScope from="88" to="95" unit="page"/>
                <date type="published" when="2016"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b21">
            <analytic>
              <title level="a" type="main">Nonlocal total variation models for multiplicative noise removal using split Bregman iteration</title>
              <author>
                <persName>
                  <forename type="first">F</forename>
                  <surname>Dong</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">H</forename>
                  <surname>Zhang</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">D</forename>
                  <surname>Kong</surname>
                </persName>
              </author>
              <idno type="doi">10.1016/j.mcm.2011.09.021</idno>
              <ptr target="https://doi.org/10.1016/j.mcm.2011.09.021"/>
            </analytic>
            <monogr>
              <title level="j">Mathematical and Computer Modelling</title>
              <imprint>
                <biblScope unit="volume">55</biblScope>
                <biblScope unit="issue">3</biblScope>
                <biblScope from="939" to="954" unit="page"/>
                <date type="published" when="2012"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b22">
            <monogr>
              <title level="m" type="main">Non-local neural networks</title>
              <author>
                <persName>
                  <forename type="first">X</forename>
                  <surname>Wang</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">R</forename>
                  <surname>Girshick</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">A</forename>
                  <surname>Gupta</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">K</forename>
                  <surname>He</surname>
                </persName>
              </author>
              <ptr target="https://arxiv.org/abs/1711.07971"/>
              <imprint>
                <date type="published" when="2017"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b23">
            <analytic>
              <title level="a" type="main">Deep learning approach to bacterial colony classification</title>
              <author>
                <persName>
                  <forename type="first">B</forename>
                  <surname>Zieliński</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">A</forename>
                  <surname>Plichta</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">K</forename>
                  <surname>Misztal</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">P</forename>
                  <surname>Spurek</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">M</forename>
                  <surname>Brzychczy-Włoch</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">D</forename>
                  <surname>Ochońska</surname>
                </persName>
              </author>
              <idno type="doi">10.1371/journal.pone.0184554</idno>
              <ptr target="https://doi.org/10.1371/journal.pone.0184554PMID"/>
            </analytic>
            <monogr>
              <title level="j">PloS ONE</title>
              <imprint>
                <biblScope unit="volume">12</biblScope>
                <biblScope unit="issue">9</biblScope>
                <biblScope unit="page">28910352</biblScope>
                <date type="published" when="2017"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b24">
            <analytic>
              <title level="a" type="main">Going deeper with convolutions</title>
              <author>
                <persName>
                  <forename type="first">C</forename>
                  <surname>Szegedy</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">W</forename>
                  <surname>Liu</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">Y</forename>
                  <surname>Jia</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">P</forename>
                  <surname>Sermanet</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">S</forename>
                  <surname>Reed</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">D</forename>
                  <surname>Anguelov</surname>
                </persName>
              </author>
              <idno type="doi">10.1109/CVPR.2015.7298594</idno>
              <ptr target="https://doi.org/10.1109/CVPR.2015.7298594"/>
            </analytic>
            <monogr>
              <title level="m">2015 IEEE Conference on Computer Vision and Pattern Recognition</title>
              <imprint>
                <date type="published" when="2015"/>
                <biblScope from="1" to="9" unit="page"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b25">
            <analytic>
              <title level="a" type="main">Accurate image super-resolution using very deep convolutional networks</title>
              <author>
                <persName>
                  <forename type="first">J</forename>
                  <surname>Kim</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">J K</forename>
                  <surname>Lee</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">K</forename>
                  <surname>Lee</surname>
                </persName>
              </author>
              <idno type="doi">10.1109/CVPR.2016.182</idno>
              <ptr target="https://doi.org/10.1109/CVPR.2016.182"/>
            </analytic>
            <monogr>
              <title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition</title>
              <imprint>
                <date type="published" when="2016"/>
                <biblScope from="1646" to="1654" unit="page"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b26">
            <analytic>
              <title level="a" type="main">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
              <author>
                <persName>
                  <forename type="first">R</forename>
                  <surname>Girshick</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">J</forename>
                  <surname>Donahue</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">T</forename>
                  <surname>Darrell</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">J</forename>
                  <surname>Malik</surname>
                </persName>
              </author>
            </analytic>
            <monogr>
              <title level="m">2014 IEEE Conference on Computer Vision and Pattern Recognition</title>
              <imprint>
                <date type="published" when="2014"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b27">
            <monogr>
              <title/>
              <idno type="doi">10.1109/CVPR.2014.81</idno>
              <ptr target="http://doi.org/10.1109/CVPR.2014.81"/>
              <imprint>
                <biblScope from="580" to="587" unit="page"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b28">
            <monogr>
              <author>
                <persName>
                  <forename type="first">R</forename>
                  <surname>Girshick</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <surname>Fast R-Cnn</surname>
                </persName>
              </author>
              <idno type="doi">10.1109/ICCV.2015.169</idno>
              <ptr target="http://doi.org/10.1109/ICCV.2015.169"/>
              <title level="m">2015 IEEE Conference on Computer Vision and Pattern Recognition</title>
              <imprint>
                <date type="published" when="2015"/>
                <biblScope from="1440" to="1448" unit="page"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b29">
            <analytic>
              <title level="a" type="main">Stacked competitive networks for noise reduction in lowdose CT</title>
              <author>
                <persName>
                  <forename type="first">W</forename>
                  <surname>Du</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">H</forename>
                  <surname>Chen</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">Z</forename>
                  <surname>Wu</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">H</forename>
                  <surname>Sun</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">P</forename>
                  <surname>Liao</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">Y</forename>
                  <surname>Zhang</surname>
                </persName>
              </author>
              <idno type="doi">10.1371/journal.pone.0190069</idno>
              <ptr target="https://doi.org/10.1371/journal.pone.0190069PMID"/>
            </analytic>
            <monogr>
              <title level="j">PloS ONE</title>
              <imprint>
                <biblScope unit="volume">12</biblScope>
                <biblScope unit="issue">12</biblScope>
                <biblScope unit="page">29267360</biblScope>
                <date type="published" when="2017"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b30">
            <analytic>
              <title level="a" type="main">Image denoising via CNNs: an adversarial approach</title>
              <author>
                <persName>
                  <forename type="first">N</forename>
                  <surname>Divakar</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">R</forename>
                  <forename type="middle">V</forename>
                  <surname>Babu</surname>
                </persName>
              </author>
              <idno type="doi">10.1109/CVPRW.2017.145</idno>
              <ptr target="http://doi.org/10.1109/CVPRW.2017.145"/>
            </analytic>
            <monogr>
              <title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
              <imprint>
                <date type="published" when="2017"/>
                <biblScope from="1076" to="1083" unit="page"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b31">
            <analytic>
              <title level="a" type="main">Beyond a Gaussian denoiser: residual learning of deep CNN for image denoising</title>
              <author>
                <persName>
                  <forename type="first">K</forename>
                  <surname>Zhang</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">W</forename>
                  <surname>Zuo</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">Y</forename>
                  <surname>Chen</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">D</forename>
                  <surname>Meng</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">L</forename>
                  <surname>Zhang</surname>
                </persName>
              </author>
              <idno type="doi">10.1109/TIP.2017.2662206</idno>
              <ptr target="https://doi.org/10.1109/TIP.2017.2662206PMID"/>
            </analytic>
            <monogr>
              <title level="j">IEEE Transactions on Image Processing</title>
              <imprint>
                <biblScope unit="volume">26</biblScope>
                <biblScope unit="issue">7</biblScope>
                <biblScope unit="page">28166495</biblScope>
                <date type="published" when="2017"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b32">
            <analytic>
              <title level="a" type="main">PCANet: A simple deep learning baseline for image classification?</title>
              <author>
                <persName>
                  <forename type="first">T H</forename>
                  <surname>Chan</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">K</forename>
                  <surname>Jia</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">S</forename>
                  <surname>Gao</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">J</forename>
                  <surname>Lu</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">Z</forename>
                  <surname>Zeng</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">Y</forename>
                  <surname>Ma</surname>
                </persName>
              </author>
              <idno type="doi">10.1109/TIP.2015.2475625</idno>
              <ptr target="https://doi.org/10.1109/TIP.2015.2475625PMID"/>
            </analytic>
            <monogr>
              <title level="j">IEEE Transactions on Image Processing</title>
              <imprint>
                <biblScope unit="volume">24</biblScope>
                <biblScope unit="issue">12</biblScope>
                <biblScope unit="page">26340772</biblScope>
                <date type="published" when="2015"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b33">
            <monogr>
              <author>
                <persName>
                  <forename type="first">A</forename>
                  <surname>Krizhevsky</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">I</forename>
                  <surname>Sutskever</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">G</forename>
                  <surname>Hinton</surname>
                </persName>
              </author>
              <idno type="doi">10.1145/3065386</idno>
              <ptr target="https://doi.org/10.1145/3065386"/>
              <title level="m">Imagenet classification with deep convolutional neural networks. In: the 25th International Conference on Neural Information Processing Systems</title>
              <imprint>
                <date type="published" when="2012"/>
                <biblScope from="1097" to="1105" unit="page"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b34">
            <analytic>
              <title level="a" type="main">Delving deep into rectifiers: surpassing human-level performance on ImageNet classification</title>
              <author>
                <persName>
                  <forename type="first">K</forename>
                  <surname>He</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">X</forename>
                  <surname>Zhang</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">S</forename>
                  <surname>Ren</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">J</forename>
                  <surname>Sun</surname>
                </persName>
              </author>
              <idno type="doi">10.1109/ICCV.2015.123</idno>
              <ptr target="https://doi.org/10.1109/ICCV.2015.123"/>
            </analytic>
            <monogr>
              <title level="m">the IEEE International Conference on Computer Vision</title>
              <imprint>
                <date type="published" when="2015"/>
                <biblScope from="1026" to="1034" unit="page"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b35">
            <monogr>
              <title level="m" type="main">Subspace clustering guided unsupervised feature selection. Pattern Recognition</title>
              <author>
                <persName>
                  <forename type="first">P</forename>
                  <surname>Zhu</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">W</forename>
                  <surname>Zhu</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">Q</forename>
                  <surname>Hu</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">C</forename>
                  <surname>Zhang</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">W</forename>
                  <surname>Zuo</surname>
                </persName>
              </author>
              <idno type="doi">10.1016/j.patcog.2017.01.016</idno>
              <ptr target="https://doi.org/10.1016/j.patcog.2017.01.016"/>
              <imprint>
                <date type="published" when="2017"/>
                <biblScope unit="volume">66</biblScope>
                <biblScope from="364" to="374" unit="page"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b36">
            <analytic>
              <title level="a" type="main">Combining neighborhood separable subspaces for classification via sparsity regularized optimization</title>
              <author>
                <persName>
                  <forename type="first">P</forename>
                  <surname>Zhu</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">Q</forename>
                  <surname>Hu</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">Y</forename>
                  <surname>Han</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">C</forename>
                  <surname>Zhang</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">Y</forename>
                  <surname>Du</surname>
                </persName>
              </author>
              <idno type="doi">10.1016/j.ins.2016.08.004</idno>
              <ptr target="https://doi.org/10.1016/j.ins.2016.08.004"/>
            </analytic>
            <monogr>
              <title level="j">Information Sciences</title>
              <imprint>
                <biblScope from="270" to="287" unit="page"/>
                <date type="published" when="2016"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b37">
            <analytic>
              <title level="a" type="main">Local adaptivity to variable smoothness for exemplar-based image regularization and representation</title>
              <author>
                <persName>
                  <forename type="first">C</forename>
                  <surname>Kervrann</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">J</forename>
                  <surname>Boulanger</surname>
                </persName>
              </author>
              <idno type="doi">10.1007/s11263-007-0096-2</idno>
              <ptr target="https://doi.org/10.1007/s11263-007-0096-2"/>
            </analytic>
            <monogr>
              <title level="j">International Journal of Computer Vision</title>
              <imprint>
                <biblScope unit="volume">79</biblScope>
                <biblScope unit="issue">1</biblScope>
                <biblScope from="45" to="69" unit="page"/>
                <date type="published" when="2008"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b38">
            <analytic>
              <title level="a" type="main">Image quality assessment: from error visibility to structural similarity</title>
              <author>
                <persName>
                  <forename type="first">Z</forename>
                  <surname>Wang</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">A C</forename>
                  <surname>Bovik</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">H R</forename>
                  <surname>Sheikh</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">E</forename>
                  <forename type="middle">P</forename>
                  <surname>Simoncelli</surname>
                </persName>
              </author>
              <idno type="doi">10.1109/TIP.2003.819861</idno>
              <ptr target="https://doi.org/10.1109/TIP.2003.819861PMID"/>
            </analytic>
            <monogr>
              <title level="j">IEEE Transactions on Image Processing</title>
              <imprint>
                <biblScope unit="volume">13</biblScope>
                <biblScope unit="issue">4</biblScope>
                <biblScope unit="page">15376593</biblScope>
                <date type="published" when="2004"/>
              </imprint>
            </monogr>
          </biblStruct>
          <biblStruct xml:id="b39">
            <analytic>
              <title level="a" type="main">Efficient reduction of speckle noise in optical coherence tomography</title>
              <author>
                <persName>
                  <forename type="first">M</forename>
                  <surname>Szkulmowski</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">I</forename>
                  <surname>Gorczynska</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">D</forename>
                  <surname>Szlag</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">M</forename>
                  <surname>Sylwestrzak</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">A</forename>
                  <surname>Kowalczyk</surname>
                </persName>
              </author>
              <author>
                <persName>
                  <forename type="first">M</forename>
                  <surname>Wojtkowski</surname>
                </persName>
              </author>
              <idno type="doi">10.1364/OE.20.001337</idno>
              <ptr target="https://doi.org/10.1364/OE.20.001337PMID"/>
            </analytic>
            <monogr>
              <title level="j">Optics Express</title>
              <imprint>
                <biblScope unit="volume">20</biblScope>
                <biblScope unit="issue">2</biblScope>
                <biblScope unit="page">22274479</biblScope>
                <date type="published" when="2012"/>
              </imprint>
            </monogr>
          </biblStruct>
        </listBibl>
      </div>
    </back>
  </text>
</TEI>
